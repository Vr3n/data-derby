# -*- coding: utf-8 -*-
"""FBref_match_scaper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vwKveJdGJDnzAzyRycMOXSKET8vR6Jkw

# Scraping the Matches of Fbref.

Provides the Detailed statistics of the match.
1. Venue and Overview of the match.
2. Manager, Captain and Referee
3. Match Summary Timeline.
4. Player stats for different categories:
   - Overall summary
   - Passing
   - Shooting
   - Defensive Actions
   - Possession
   - Misc
5. Goalkeeper Statistics
"""

"""## Importing Necessary Packages"""

import asyncio
import httpx
import requests
import pandas as pd
from bs4 import BeautifulSoup

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/123.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
    "Connection": "keep-alive",
}

cookies = {
    "cf_clearance": "Z17ygU7F_VRGKdvmRsGNHK.ljFCJ_A5cSHZYg3MCL5I-1749221789-1.2.1.1-_P5zkgWH0M0dEpnBgUXAMKJWGnIS4wRY.QtqzUgSmoJ7upATZH6TQRp236F.dKTFjnccHncU_4fjDOT_YuDFTmqwH.GaHHpFzVNuXf1RLtUrnJ_QXl7wpGKwo0.S0_DksiwqGMxa4IfudSR1yJOfhcMhtDzGIZQ7VS0I5Fm_3Tr58E_3uzu_t6NfDyseSRgs66HG3pHRo7m3spJNdXtDiVVV_B7cwYefP2N13ZSUpmVZZR8U_LOejgz8f2L9MoyptWq0r04JLMsgCsltkGN1AcqzBI1tCoZ3MkHZxA6P_aMZVHU1bzVMCqjV4Wgjr_RW9E9z7u68YithtwlhAfm1lY2MZii9nbDfuzgeaA0kkWCbCQjhG8XFAt8VhMCSF8Qf",
    "sr_lang_views-en": "-0.5",
    "sr_note_box_countdown": "28",
    "osano_consentmanager_uuid": "db3494e7-77ad-47c8-a349-c5d5b2c0dcf0",
    "sr_n": "1|Mon, 26 May 2025 04:53:58 GMT",
    "__cf_bm": "uuspikRgq3FxqY5ZXX.16j7WCwcuCvy3l8O9t8qnB2E-1749221779-1.0.1.1-7BpMvKi6AhtCkaV7U4B24d379vSJS81sm8S1fxoZkS0cIq1DPRPv3.avwYS0WblgC3Gax4hJodwdy0USh9dKOZJflzbH0zlwdFnOk.MRgxQ",
    "srcssfull": "yes",
    "is_live": "true"
}

res = requests.get("https://fbref.com/en/matches/a71ce7d1/Barcelona-Mallorca-April-22-2025-La-Liga", headers=headers)

# async with httpx.AsyncClient() as client:
#   res = await client.get("https://fbref.com/en/matches/a71ce7d1/Barcelona-Mallorca-April-22-2025-La-Liga", headers=headers, cookies=cookies)

res.status_code

res.content

soup = BeautifulSoup(res.content)

soup

header = soup.select_one("div#content > h1")

"""## Match Info

Match name and Date
"""

header_split = header.text.split('‚Äì')
match_name = header_split[0].split('Match')[0].strip()
match_date = header_split[1].strip()

match_info = {
    'name': match_name,
    'date': match_date
}

print(match_info)

match_score_summary = dict()

score_box = soup.select_one("div.scorebox")

"""## Score Box"""

def parse_score_box(team_div):
  name = team_div.find('strong').find("a").text
  logo = team_div.find('img')['src']
  score = team_div.find('div', class_='score').text.strip()
  xg = team_div.find('div', class_='score_xg').text.strip()
  record = team_div.find_all('div')[5].text.strip()  # the W-D-L string

  datapoints = team_div.find_all('div', class_='datapoint')

  # Safe parsing into a dict: { "Manager": "Hansi Flick", "Captain": "Ronald Ara√∫jo" }
  info = {}
  for div in datapoints:
      try:
          label = div.find('strong').text.strip().replace("\xa0", " ")
          if div.find('a'):
              value = div.find('a').text.strip().replace("\xa0", " ")
          else:
              value = div.get_text(strip=True).split(':', 1)[1].strip().replace("\xa0", " ")
          info[label] = value
      except Exception as e:
          print(f"Warning: Failed to parse datapoint: {div} | Error: {e}")

  # Access the values
  manager = info.get('Manager')
  captain = info.get('Captain')

  return {
      'team_name': name,
      'logo_url': logo,
      'score': score,
      'xg': xg,
      'record': record,
      'manager': manager,
      'captain': captain
  }

scorebox = soup.find('div', class_='scorebox')
teams = scorebox.find_all('div', recursive=False)

home_team = parse_score_box(teams[0])
away_team = parse_score_box(teams[1])

print("Home Team:", home_team)
print("Away Team:", away_team)

home_team['team_id'] = home_team['logo_url'].split('/')[-1].split(".")[0]
away_team['team_id'] = away_team['logo_url'].split('/')[-1].split(".")[0]

"""## Scorebox Meta"""

scorebox_meta = soup.find("div", class_="scorebox_meta").find_all("div")[-3:-1]

attendance = scorebox_meta[0].text.split(": ")[-1].strip()
venue = scorebox_meta[1].text.split(": ")[-1].strip()

match_info['attendance'] = attendance
match_info['venue'] = venue

print(match_info)

"""## Lineups & Formations"""

ht_soup = soup.find("div", id="a", class_="lineup")
at_soup = soup.find("div", id="b", class_="lineup")

"""### Formations"""

def extract_formation(lineup_soup):
  import re

  try:
      text = lineup_soup.find("th").text  # Example: "Barcelona (4-2-3-1)"
      match = re.search(r'\(([\d-]+)\)', text)
      formation = match.group(1) if match else None
      return formation
  except Exception as e:
      print(f"Error extracting formation: {e}")
      return None

home_team['formation'] = extract_formation(ht_soup)
away_team['formation'] = extract_formation(at_soup)

"""### Player Linups"""

players = ht_soup.find_all("tr")[1:]

starting_lineup = list()
benched_lineup = list()
benches = False
for player in players:
  temp_dict = dict()
  if player.text == "Bench":
    benches = True
    continue


  temp_dict['number'] = player.find("td").text
  temp_dict['link'] = player.find("a").get("href")
  temp_dict['name'] = player.find("a").text

  if player.find("div", class_="event_icon"):
    event = player.find("div", class_="event_icon").get('class')[-1]
    temp_dict["event"] = event

  if benches:
    benched_lineup.append(temp_dict)
  else:
    starting_lineup.append(temp_dict)

"""## Match Events"""

match_events = soup.find("div", id="events_wrap")

home_events = soup.find_all("div", class_="event a")
away_events = soup.find_all("div", class_="event b")

event = home_events[0]

timing, score = event.find_all("div")[0].get_text(strip=True).split(";")

timing = timing[:2]
{ 'time': timing, 'score': score }

event_type_div = event.find("div", class_="event_icon")
event_type = event_type_div['class'][1] if event_type_div else None

icon_div = event.find("div", class_="event_icon")
if not icon_div or not icon_div.has_attr("class"):
  pass

event_type = icon_div["class"][1]

print(event_type)

event_block = icon_div.find_next_sibling("div")

if event_type == "goal":
  if event_block.find("small") and event_block.find("small").find("a"):
    players = []
    scorer = event_block.find("a")
    if scorer:
      players.append({
          "event": "goal",
          "name": scorer.text.strip(),
          "link": scorer['href']
      })

    # Assist
    assist = event_block.find("small")
    if assist:
      assist_player = assist.find("a")
      if assist_player:
        players.append({
            "event": "assist",
            "name": assist_player.text.strip(),
            "link": assist_player['href']
        })

subs_event = home_events[1]

icon_div = subs_event.find("div", class_="event_icon")
if not icon_div or not icon_div.has_attr("class"):
  pass

event_type = icon_div["class"][1]

print(event_type)

players = subs_event.find_all("a")
score = subs_event.find_next("div").text.rsplit(";")[1].strip()
timing = subs_event.find_next("div").text.split("&")[0].strip()
if len(players) == 2:
  sub_event = [
      {
          "event": "sub out",
          "name": players[0].text.strip(),
          "link": players[0]["href"]
      },
      {
          "event": "sub in",
          "name": players[1].text.strip(),
          "link": players[1]["href"]
      },
  ]

print(sub_event)

event = away_events[0]

event_type = event.find("div", class_="event_icon").get("class")[1]

player = event.find("a")

event_type

{ event_type, player.text.strip(), player['href']}

def extract_goal(event_block):
    """Handles goal without assist."""
    player = event_block.find("a")
    return [{
        "event": "goal",
        "name": player.text.strip(),
        "link": player["href"]
    }] if player else []


def extract_goal_with_assist(event_block):
    """Handles goal with assist."""
    players = []

    # Goal scorer
    scorer = event_block.find("a")
    if scorer:
        players.append({
            "event": "goal",
            "name": scorer.text.strip(),
            "link": scorer["href"]
        })

    # Assist
    assist = event_block.find("small")
    if assist:
        assist_player = assist.find("a")
        if assist_player:
            players.append({
                "event": "assist",
                "name": assist_player.text.strip(),
                "link": assist_player["href"]
            })

    return players


def extract_substitution(event_block):
    """Handles substitution events."""
    players = event_block.find_all("a")
    if len(players) == 2:
        return [
            {
                "event": "sub in",
                "name": players[1].text.strip(),
                "link": players[1]["href"]
            },
            {
                "event": "sub out",
                "name": players[0].text.strip(),
                "link": players[0]["href"]
            }
        ]
    return []


def extract_card(event_block, card_type: str):
    """Handles yellow and red card events."""
    player = event_block.find("a")
    return [{
        "event": card_type,
        "name": player.text.strip(),
        "link": player["href"]
    }] if player else []

def extract_match_events(event_html):
  events = []
  for event_div in event_html:
    icon_div = event_div.find("div", class_="event_icon")
    if not icon_div or not icon_div.has_attr("class"):
      continue

    event_type = icon_div["class"][1]

    event_block = icon_div.find_next_sibling("div")

    score = event_div.find_next("div").text.rsplit(";")[1].strip()
    timing = event_div.find_next("div").text.split("&")[0].strip()

    if event_type == "goal":
      if event_block.find("small") and event_block.find("small").find("a"):
        events.append({"time": timing, "score": score, "event_type": event_type, "event": extract_goal_with_assist(event_block)})
      else:
        events.append({"time": timing, "score": score, "event_type": event_type, "event": extract_goal(event_block)})

    elif event_type == "substitute_in":
      events.append({"time": timing, "score": score, "event_type": event_type, "event": extract_substitution(event_block)})

    elif event_type == "yellow_card":
      events.append({"time": timing, "score": score, "event_type": event_type, "event": extract_card(event_block, "yellow card")})

    elif event_type == "red_card":
      events.append({"time": timing, "score": score, "event_type": event_type, "event": extract_card(event_block, "red card")})

  return events

home_events_list = extract_match_events(home_events)
away_events_list = extract_match_events(away_events)

home_events_list

away_events_list

"""## Team Stats"""

team_stats = soup.find("div", id="team_stats")

def extract_team_stats(rows: str) -> dict:
    """
    Extracts possession, passing accuracy, shots on target, and saves for both teams from match summary HTML.

    Args:
        html (str): HTML string containing match stat rows.

    Returns:
        dict: Stats for both teams, keyed by team names.
    """
    team1, team2 = [th.get_text(strip=True) for th in rows[0].find_all("th")]
    stats = {team1: {}, team2: {}}

    def to_int(text: str) -> int:
        return int(re.search(r"\d+", text).group()) if text else 0

    def parse_generic(text: str) -> dict:
        nums = list(map(int, re.findall(r"\d+", text)))
        if len(nums) == 3:
            return {"completed": nums[0], "total": nums[1], "accuracy": nums[2]}
        elif len(nums) == 2:
            return {"completed": nums[0], "total": nums[1], "accuracy": to_int(text)}
        return {"completed": 0, "total": 0, "accuracy": 0}

    def parse_shots(text: str) -> dict:
        nums = list(map(int, re.findall(r"\d+", text)))
        if len(nums) >= 3:
            return {"on_target": nums[0], "total_shots": nums[1], "percentage": nums[2]}
        return {"on_target": 0, "total_shots": 0, "percentage": 0}

    def parse_saves(text: str) -> dict:
        nums = list(map(int, re.findall(r"\d+", text)))
        if len(nums) >= 3:
            return {"shots_saved": nums[0], "shots_faced": nums[1], "percentage": nums[2]}
        return {"shots_saved": 0, "shots_faced": 0, "percentage": 0}

    label_map = {
        "possession": lambda td: to_int(td.get_text()),
        "passing accuracy": lambda td: parse_generic(td.get_text()),
        "shots on target": lambda td: parse_shots(td.get_text()),
        "saves": lambda td: parse_saves(td.get_text()),
    }

    i = 1
    while i < len(rows):
        header = rows[i].find("th")
        if not header:
            i += 1
            continue

        label = header.get_text(strip=True).lower()
        i += 1
        if i >= len(rows):
            break

        cells = rows[i].find_all("td")
        if len(cells) != 2 or label not in label_map:
            i += 1
            continue

        parser = label_map[label]
        stat_key = label.replace(" ", "_")

        stats[team1][stat_key] = parser(cells[0])
        stats[team2][stat_key] = parser(cells[1])

        i += 1

    return stats

import re

extract_team_stats(team_stats.find_all("tr"))

team_stats_extra = soup.find("div", id="team_stats_extra")

def extract_extra_team_stats(container: str) -> dict:
    """
    Extracts extra team stats (e.g. fouls, corners, tackles) for both teams from the match HTML.

    Args:
        html (str): HTML content containing the #team_stats_extra section.

    Returns:
        dict: Dictionary of stats for each team, keyed by team name.
    """
    stats = {}
    for block in container.find_all("div", recursive=False):
        divs = block.find_all("div")
        if len(divs) < 3:
            continue

        team1 = divs[0].get_text(strip=True)
        team2 = divs[2].get_text(strip=True)

        # Initialize team dicts if not already
        stats.setdefault(team1, {})
        stats.setdefault(team2, {})

        # Remaining divs contain groups of 3: [val1, label, val2]
        for i in range(3, len(divs), 3):
            val1 = divs[i].get_text(strip=True)
            label = divs[i + 1].get_text(strip=True).lower().replace(" ", "_")
            val2 = divs[i + 2].get_text(strip=True)

            if val1.isdigit():
                stats[team1][label] = int(val1)
            if val2.isdigit():
                stats[team2][label] = int(val2)

    return stats

team_stats_extra_dict = extract_extra_team_stats(team_stats_extra)

team_stats_extra_dict

"""## All Player Stats

div_stats_206d90db_passing
The divs with different stat types have
`div_starts_{team_id}_{stat_type}`

"""

match_info

player_stats_table = soup.find("div", id=f"all_player_stats_{home_team['team_id']}")

player_stats_types = [x.get('data-show').split("_")[-1] if 'passing_type' not in x.get('data-show') else '_'.join(x.get('data-show').split("_")[-2:]) for x in soup.find("div", class_="filter switcher").find_all("a")]

player_stats_types

def try_parse_number(text: str) -> int | float | str | None:
    """
    Attempts to parse a string to int or float.

    Args:
        text (str): Text to parse.

    Returns:
        int | float | str | None: Parsed number or original text.
    """
    try:
        return int(text)
    except ValueError:
        try:
            return float(text)
        except ValueError:
            return text if text else None

def parse_player_stats_table(table, stat_type = None, team_id = None):
    """
    Parses a player stats table and returns player data dictionaries with debug logging.

    Args:
        table (bs4.element.Tag): BeautifulSoup table tag containing player data.
        stat_type (str): Stat type being parsed (e.g., 'passing', 'summary').
        team_id (str): The team ID (used for debugging).

    Returns:
        list[dict]: List of player stat dictionaries.
    """
    players = []
    rows = table.find_all("tr")
    headers = [
        cell.get("data-stat")
        for cell in rows[0].find_all(["th", "td"])
    ]

    for i, row in enumerate(rows):
        if not row.find("th", { "data-stat": "player" }):
            continue

        player_data = {}
        try:
            for cell in row.find_all(["th", "td"]):
                key = cell.get("data-stat")
                if not key:
                  if stat_type and team_id:
                    print(f"‚ö†Ô∏è Missing data-stat at row {i} for stat_type '{stat_type}' (team_id: {team_id})")
                  else:
                    print(f"‚ö†Ô∏è Missing data-stat at row {i}")
                  continue

                text = cell.get_text(strip=True)
                value = try_parse_number(text)

                if key == "player":
                    player_data["name"] = text
                    player_data["link"] = cell.find("a")["href"] if cell.find("a") else None
                    player_data["fbref_id"] = cell.find("a")["href"].split("/")[-2] if cell.find("a") else None
                elif key == "age":
                    player_data["age"] = text.split("-")[0]  # Only the years
                else:
                    player_data[key] = value

            players.append(player_data)

        except Exception as e:
            print(f"‚ùóÔ∏è Error parsing row {i} for stat_type '{stat_type}' (team_id: {team_id})")
            print(f"   -> Row HTML: {row}")
            print(f"   -> Exception: {e}")

    return players

def extract_player_stats_type(soup, team_id, stat_type):
  """
  Extracts player statistics for a specific stat type (e.g., passing, summary) from a team stats table.

  Args:
      html (str): Full HTML string containing the stat table.
      team_id (str): Team identifier (e.g., '206d90db').
      stat_type (str): Stat type (e.g., 'passing', 'summary', 'misc_stats').

  Returns:
      list[dict]: List of player stat dictionaries.
  """
  table_id = f"stats_{team_id}_{stat_type}"
  print(f"\nüîç Extracting stat_type: '{stat_type}' for team_id: '{team_id}'")
  table = soup.find("table", id=table_id)

  if not table:
    print(f"‚ùå Table with id='{table_id}' not found.")
    return []

  players = parse_player_stats_table(table, stat_type, team_id)

  return players

from collections import defaultdict

def extract_all_player_stats_grouped(player_stats_table, team_id, player_stats_types):
  """Group all stat types by player.

  Args:
      player_stats_table (Tag): BeautifulSoup Tag representing the full stats table.
      team_id (str): Team ID to match players.
      player_stats_types (list[str]): List of stat types (e.g., 'passing', 'summary').

  Returns:
      list[dict]: One dict per player, with combined stat types nested under keys.
  """

  grouped_stats = defaultdict(lambda:{
    'name': None,
    'link': None,
    'fbref_id': None
  })

  for stat_type in player_stats_types:
    try:
      player_rows = extract_player_stats_type(player_stats_table, team_id=team_id, stat_type=stat_type)[1:-1]
    except Exception as e:
      print(f"[ERROR] Failed to extract player stats for stat_type='{stat_type}', team_id='{team_id}': {e}")
      continue

    for idx, row in enumerate(player_rows):
      try:
        player_id = row["fbref_id"]
        if grouped_stats[player_id]['fbref_id'] is None:
          grouped_stats[player_id]['fbref_id'] = player_id
        # row.pop("player")
        grouped_stats[player_id]['name'] = row.pop("name")
        grouped_stats[player_id]['link'] = row.pop("link")
        grouped_stats[player_id][f"{stat_type}_stats"] = row
      except KeyError as ke:
        print(f"[MISSING KEY] stat_type='{stat_type}', team_id='{team_id}', row_index={idx}, row={row}")
        print(f"MIssing Key: {ke}")
      except Exception as e:
        print(f"[ERROR] Processing row failed: stat_type='{stat_type}', team_id='{team_id}', row_index={idx}, row={row}")
        print(f"Exception: {e}")


  # extracting gk stats.
  gk_stat_table = soup.find("table", id=f"keeper_stats_{team_id}")

  if gk_stat_table:
    print(f"\nüîç Extracting stat_type: 'keeper_stats' for team_id: '{team_id}'")
    gk_rows = parse_player_stats_table(gk_stat_table)
    if len(gk_rows) <= 2:
      gk_rows = gk_rows[-1:]
      print(f"[WARNING] Not enough rows to slice for keeper_stats: got {len(gk_rows)} rows")
    else:
        gk_rows = gk_rows[1:-1]
    for idx, row in enumerate(gk_rows):
      try:
        player_id = row["fbref_id"]
        if grouped_stats[player_id]['fbref_id'] is None:
          grouped_stats[player_id]['fbref_id'] = player_id
        # row.pop("player")
        grouped_stats[player_id]['name'] = row.pop("name")
        grouped_stats[player_id]['link'] = row.pop("link")
        grouped_stats[player_id]['keeper_stats'] = row
      except KeyError as ke:
        print(f"[MISSING KEY] stat_type='keeper_stats', team_id='{team_id}', row_index={idx}, row={row}")
        print(f"MIssing Key: {ke}")
      except Exception as e:
        print(f"[ERROR] Processing row failed: stat_type='keeper_stats', team_id='{team_id}', row_index={idx}, row={row}")
        print(f"Exception: {e}")


  return list(grouped_stats.values())

home_team_player_stats = extract_all_player_stats_grouped(soup, team_id=home_team["team_id"], player_stats_types=player_stats_types)
away_team_player_stats = extract_all_player_stats_grouped(soup, team_id=away_team["team_id"], player_stats_types=player_stats_types)

home_team_player_stats

away_team_player_stats

